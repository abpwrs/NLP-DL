{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import multiprocessing as mp\n",
    "PROJ_NAME = \"SURVEY_TOXIC\"\n",
    "LABELS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "NUM_CLASSES = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\",'r') as f:\n",
    "    config_file = json.load(f)[\"BASE_CONFIG\"]\n",
    "with open(config_file,'r') as f:\n",
    "    config = json.load(f)\n",
    "data_dir=os.path.join(config[\"data_dir\"],PROJ_NAME)\n",
    "model_dir=os.path.join(config[\"model_dir\"],PROJ_NAME)\n",
    "out_dir=os.path.join(config[\"out_dir\"],PROJ_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to evaluate\n",
    "# RandomForest\n",
    "# SVC, NuSVC -- support vector methods \n",
    "# Nearest Neighbor Classification\n",
    "# Voting Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.cluster import DBSCAN, KMeans, MeanShift, AgglomerativeClustering\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clfs = {\n",
    "    'ensemble' : {\n",
    "        'rfc':RandomForestClassifier(n_estimators=20)},\n",
    "    'svm' : {\n",
    "        'svc':SVC(), \n",
    "        'nsc':NuSVC()},\n",
    "    'tree' : {\n",
    "        'dtc':DecisionTreeClassifier()},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_class_balance(df: pd.DataFrame, interested_labels, thresh):\n",
    "    dfs = {}\n",
    "    null = df.copy()\n",
    "    for name in interested_labels:\n",
    "        dfs[name] = df.loc[(df[name] == 1)]\n",
    "        null.drop(null[null[name]==1].index,axis=0,inplace=True)\n",
    "        \n",
    "    print(\"NULL:\", 100*(len(null)/len(df)))\n",
    "    for name, d in dfs.items():\n",
    "        print(\"Initial percentage of DF for\", name, \"is\", 100*(len(d)/len(df)))\n",
    "    \n",
    "    print(\"Each label will now have at least\", thresh*100,\"% of the origional df size\")\n",
    "    adjusted_df = null.sample(int(thresh*len(df))) # get a subsample of null cases\n",
    "    \n",
    "\n",
    "    for n, d in dfs.items():\n",
    "        i=0\n",
    "        for times in range(math.ceil((thresh/(len(d)/len(df))+1))):\n",
    "            adjusted_df = adjusted_df.append(d)\n",
    "            i+=1\n",
    "        print(n,\"upsampled\",i,\"times\")\n",
    "    return adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL: 89.83211235124176\n",
      "Initial percentage of DF for toxic is 9.584448302009765\n",
      "Initial percentage of DF for severe_toxic is 0.9995550569965721\n",
      "Initial percentage of DF for obscene is 5.2948217407925\n",
      "Initial percentage of DF for threat is 0.2995531769557125\n",
      "Initial percentage of DF for insult is 4.936360616904074\n",
      "Initial percentage of DF for identity_hate is 0.8804858025581089\n",
      "Each label will now have at least 14.285714285714285 % of the origional df size\n",
      "toxic upsampled 3 times\n",
      "severe_toxic upsampled 16 times\n",
      "obscene upsampled 4 times\n",
      "threat upsampled 49 times\n",
      "insult upsampled 4 times\n",
      "identity_hate upsampled 18 times\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "a_df = adjust_class_balance(df, LABELS, 1/(len(LABELS)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208213.000000</td>\n",
       "      <td>208213.000000</td>\n",
       "      <td>208213.000000</td>\n",
       "      <td>208213.000000</td>\n",
       "      <td>208213.000000</td>\n",
       "      <td>208213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.854505</td>\n",
       "      <td>0.254446</td>\n",
       "      <td>0.671385</td>\n",
       "      <td>0.147719</td>\n",
       "      <td>0.653269</td>\n",
       "      <td>0.229448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.435550</td>\n",
       "      <td>0.469711</td>\n",
       "      <td>0.354822</td>\n",
       "      <td>0.475931</td>\n",
       "      <td>0.420479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  208213.000000  208213.000000  208213.000000  208213.000000   \n",
       "mean        0.854505       0.254446       0.671385       0.147719   \n",
       "std         0.352600       0.435550       0.469711       0.354822   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       1.000000       0.000000   \n",
       "75%         1.000000       1.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  208213.000000  208213.000000  \n",
       "mean        0.653269       0.229448  \n",
       "std         0.475931       0.420479  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         1.000000       0.000000  \n",
       "75%         1.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    i = 0\n",
    "    l = len(data)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = [ stemmer.stem(lemmatizer.lemmatize(w)) for w in stopwords.words('english')]\n",
    "    data = [ ' '.join(' '.join(phrase.split(punctuation)).split()) for phrase in data]\n",
    "    cleaned = []\n",
    "    for phrase in data:\n",
    "        if i% 10000 == 0:\n",
    "            print(i/l)\n",
    "        i+=1\n",
    "        temp = []\n",
    "        for word in word_tokenize(phrase):\n",
    "            c_w = stemmer.stem(lemmatizer.lemmatize(word))\n",
    "            if c_w not in stops:\n",
    "                temp.append(c_w)\n",
    "        cleaned.append(temp)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.04802774082309942\n",
      "0.09605548164619884\n",
      "0.14408322246929828\n",
      "0.19211096329239769\n",
      "0.24013870411549712\n",
      "0.28816644493859656\n",
      "0.33619418576169596\n",
      "0.38422192658479537\n",
      "0.4322496674078948\n",
      "0.48027740823099424\n",
      "0.5283051490540936\n",
      "0.5763328898771931\n",
      "0.6243606307002925\n",
      "0.6723883715233919\n",
      "0.7204161123464914\n",
      "0.7684438531695907\n",
      "0.8164715939926902\n",
      "0.8644993348157896\n",
      "0.912527075638889\n",
      "0.9605548164619885\n"
     ]
    }
   ],
   "source": [
    "clean = clean_data(a_df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"CLEAN_ADJUSTED.txt\"),'w') as f:\n",
    "    for phrase in clean:\n",
    "        f.write(\"%s\\n\" % ' '.join(phrase))\n",
    "a_df.to_csv(os.path.join(data_dir, \"ADJUSTED.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.04802774082309942\n",
      "0.09605548164619884\n",
      "0.14408322246929828\n",
      "0.19211096329239769\n",
      "0.24013870411549712\n",
      "0.28816644493859656\n",
      "0.33619418576169596\n",
      "0.38422192658479537\n",
      "0.4322496674078948\n",
      "0.48027740823099424\n",
      "0.5283051490540936\n",
      "0.5763328898771931\n",
      "0.6243606307002925\n",
      "0.6723883715233919\n",
      "0.7204161123464914\n",
      "0.7684438531695907\n",
      "0.8164715939926902\n",
      "0.8644993348157896\n",
      "0.912527075638889\n",
      "0.9605548164619885\n"
     ]
    }
   ],
   "source": [
    "def bag_of_words(data:np.array):\n",
    "    i=0\n",
    "    l = len(data)\n",
    "    a = []\n",
    "    for sent in data:\n",
    "            for word in sent:\n",
    "                a.append(word)\n",
    "    bag = list(dict(Counter(a).most_common(2000)).keys())\n",
    "    \n",
    "    vecs = []\n",
    "    i=0\n",
    "    for sent in data:\n",
    "        if i % 10000 == 0:\n",
    "            print(i/l)\n",
    "        i+=1\n",
    "        vec = []\n",
    "        for word in bag:\n",
    "            vec.append(int(word in sent))\n",
    "        vecs.append(vec)\n",
    "    return bag, np.array(vecs)\n",
    "\n",
    "y = np.array(a_df[LABELS])\n",
    "bag, X = bag_of_words(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_imports\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Save an array to a binary file in NumPy ``.npy`` format.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "file : file, str, or pathlib.Path\n",
       "    File or filename to which the data is saved.  If file is a file-object,\n",
       "    then the filename is unchanged.  If file is a string or Path, a ``.npy``\n",
       "    extension will be appended to the file name if it does not already\n",
       "    have one.\n",
       "arr : array_like\n",
       "    Array data to be saved.\n",
       "allow_pickle : bool, optional\n",
       "    Allow saving object arrays using Python pickles. Reasons for disallowing\n",
       "    pickles include security (loading pickled data can execute arbitrary\n",
       "    code) and portability (pickled objects may not be loadable on different\n",
       "    Python installations, for example if the stored objects require libraries\n",
       "    that are not available, and not all pickled data is compatible between\n",
       "    Python 2 and Python 3).\n",
       "    Default: True\n",
       "fix_imports : bool, optional\n",
       "    Only useful in forcing objects in object arrays on Python 3 to be\n",
       "    pickled in a Python 2 compatible way. If `fix_imports` is True, pickle\n",
       "    will try to map the new Python 3 names to the old module names used in\n",
       "    Python 2, so that the pickle data stream is readable with Python 2.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "savez : Save several arrays into a ``.npz`` archive\n",
       "savetxt, load\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from tempfile import TemporaryFile\n",
       ">>> outfile = TemporaryFile()\n",
       "\n",
       ">>> x = np.arange(10)\n",
       ">>> np.save(outfile, x)\n",
       "\n",
       ">>> outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
       ">>> np.load(outfile)\n",
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/gen/lib/python3.6/site-packages/numpy/lib/npyio.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.save(os.path.join(data_dir, \"X.npy\"), X)\n",
    "np.save(os.path.join(data_dir, \"Y.npy\"), y)\n",
    "np.save(os.path.join(data_dir, \"BAG.npy\"), np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:50000], y[:50000], test_size=0.33)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for toxic\n",
      "(33500,) 1 0\n",
      "(16500,) 1 0\n",
      "training rfc\n",
      "rfc has acc of: 0\n",
      "training svc\n"
     ]
    }
   ],
   "source": [
    "for index, label in enumerate(LABELS):\n",
    "    print(\"training for %s\"%label)\n",
    "    y_temp_train = y_train[:,index]\n",
    "    print(y_temp_train.shape,max(y_temp_train),min(y_temp_train))\n",
    "    y_temp_test = y_test[:,index]\n",
    "    print(y_temp_test.shape,max(y_temp_test),min(y_temp_test))\n",
    "    for classifier_type, dic in clfs.items():\n",
    "        for name, clf in dic.items():\n",
    "            print(\"training %s\"%name)\n",
    "            clfs[classifier_type][name].fit(X_train, y_temp_train)\n",
    "            score = clfs[classifier_type][name].score(X_test, y_temp_test)\n",
    "            print(\"%s has acc of: %d\" %(name,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
