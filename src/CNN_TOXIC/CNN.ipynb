{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-04713228be61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from matplotlib import pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "from pprint import pprint as pp\n",
    "from collections import Counter\n",
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "import re\n",
    "NUM_CLASSES=6\n",
    "NUM_FC1 = 800\n",
    "NUM_FC2 = 600\n",
    "MAX_COMMENT_LENGTH = 1000\n",
    "FEATUR_VECTOR_LENGTH = 1000\n",
    "LABELS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "PROJ_NAME = \"CNN_TOXIC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print env stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4462979149109047118\n",
      "]\n",
      "CPUs: 56\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "print(\"CPUs:\", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, stopwords and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/abpwrs/NLP-DL/config.json\", \"rb\") as f:\n",
    "    config = json.load(f) # load config\n",
    "data_dir = os.path.join(config[\"data_dir\"],PROJ_NAME)\n",
    "model_dir = os.path.join(config[\"model_dir\"],PROJ_NAME)\n",
    "with open(os.path.join(data_dir,\"stopwords.txt\"), \"r\") as f:\n",
    "    stopwords = f.readlines() # load stopwords                              \n",
    "stopwords = set([i.split()[0] for i in stopwords]) # remove new line characters (\\n) from strings\n",
    "df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colum names and basic description of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id',\n",
      " 'comment_text',\n",
      " 'toxic',\n",
      " 'severe_toxic',\n",
      " 'obscene',\n",
      " 'threat',\n",
      " 'insult',\n",
      " 'identity_hate']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>394.073221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>590.720282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  comment_length  \n",
       "count  159571.000000  159571.000000   159571.000000  \n",
       "mean        0.049364       0.008805      394.073221  \n",
       "std         0.216627       0.093420      590.720282  \n",
       "min         0.000000       0.000000        6.000000  \n",
       "25%         0.000000       0.000000       96.000000  \n",
       "50%         0.000000       0.000000      205.000000  \n",
       "75%         0.000000       0.000000      435.000000  \n",
       "max         1.000000       1.000000     5000.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pp(list(df.columns))\n",
    "# df['comment_length'] = df.comment_text.str.len()\n",
    "# df['comment_length'].hist()\n",
    "# plt.show()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_class_balance(df: pd.DataFrame, interested_labels, thresh):\n",
    "    dfs = {}\n",
    "    null = df.copy()\n",
    "    for name in interested_labels:\n",
    "        dfs[name] = df.loc[(df[name] == 1)]\n",
    "        null.drop(null[null[name]==1].index,axis=0,inplace=True)\n",
    "        \n",
    "    print(\"NULL:\", 100*(len(null)/len(df)))\n",
    "    for name, d in dfs.items():\n",
    "        print(\"Initial percentage of DF for\", name, \"is\", 100*(len(d)/len(df)))\n",
    "    \n",
    "    print(\"Each label will now have at least\", thresh*100,\"% of the origional df size\")\n",
    "    adjusted_df = null.sample(int(thresh*len(df))) # get a subsample of null cases\n",
    "    \n",
    "\n",
    "    for n, d in dfs.items():\n",
    "        i=0\n",
    "        for times in range(math.ceil((thresh/(len(d)/len(df))+1))):\n",
    "            adjusted_df = adjusted_df.append(d)\n",
    "            i+=1\n",
    "        print(n,\"upsampled\",i,\"times\")\n",
    "    return adjusted_df\n",
    "\n",
    "df = adjust_class_balance(df, LABELS, 1/(len(LABELS)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDIT: https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "def clean_comment(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# CODE TO GENERATE CLEANED COMMENTS\n",
    "cleaned = [[lemmatizer.lemmatize(x) for x in nltk.word_tokenize(clean_comment(comment)) if x.isalpha() and not x in stopwords] for comment in df[\"comment_text\"]]\n",
    "np.save(os.path.join(data_dir, \"cleaned.npy\"), cleaned)\n",
    "# CODE TO LOAD CLEANED COMMENTS FROM FILE\n",
    "# cleaned = np.load(os.path.join(data_dir, \"cleaned.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data:np.array):\n",
    "    a = []\n",
    "    for sent in data:\n",
    "            for word in sent:\n",
    "                a.append(word)\n",
    "    bag = list(dict(Counter(a).most_common(FEATUR_VECTOR_LENGTH)).keys())\n",
    "    \n",
    "    vecs = []\n",
    "    for sent in data:\n",
    "        vec = []\n",
    "        for word in bag:\n",
    "            vec.append(int(word in sent))\n",
    "        vecs.append(vec)\n",
    "    return bag, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag, vecs = bag_of_words(cleaned)\n",
    "vecs = np.array(vecs)\n",
    "np.save(os.path.join(data_dir, \"vectors.npy\"), vecs)\n",
    "with open(os.path.join(data_dir, \"bag.txt\"), 'w') as f:\n",
    "    for word in bag:\n",
    "        f.write(word+ \"\\n\")\n",
    "# vecs = np.load(os.path.join(data_dir, \"vectors.npy\")).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(filters=5, kernel_size=3, strides=2, padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=3, strides=2, padding='same'))\n",
    "model.add(tf.keras.layers.Conv1D(filters=5, kernel_size=3, strides=2, padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=3, strides=2, padding='same'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=NUM_FC1, activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "model.add(tf.keras.layers.Dense(units=NUM_FC2, activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer='adam', metrics=[tf.keras.metrics.mae,tf.keras.metrics.mse,tf.keras.metrics.categorical_crossentropy, tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106912, 1000)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vecs, labels, test_size=0.33)\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, FEATUR_VECTOR_LENGTH)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, FEATUR_VECTOR_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_dir = os.path.join(model_dir,\"uncorrected_\"+strftime(\"%Y-%m-%d_%H:%M:%S\", gmtime()))\n",
    "if not os.path.isdir(output_model_dir):\n",
    "    os.makedirs(output_model_dir)\n",
    "checkpoint_path = os.path.join(output_model_dir,\"cp-{epoch:04d}.ckpt\")\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1,\n",
    "    # Save weights, every 5-epochs.\n",
    "    period=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 4s 33us/step - loss: 0.3115 - mean_absolute_error: 0.3854 - mean_squared_error: 0.2484 - categorical_crossentropy: 0.3115 - categorical_accuracy: 0.9858 - val_loss: 0.3016 - val_mean_absolute_error: 0.3297 - val_mean_squared_error: 0.2207 - val_categorical_crossentropy: 0.3016 - val_categorical_accuracy: 0.9936\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 3s 29us/step - loss: 0.2918 - mean_absolute_error: 0.3114 - mean_squared_error: 0.2093 - categorical_crossentropy: 0.2918 - categorical_accuracy: 0.9929 - val_loss: 0.2949 - val_mean_absolute_error: 0.3041 - val_mean_squared_error: 0.2047 - val_categorical_crossentropy: 0.2949 - val_categorical_accuracy: 0.9894\n",
      "\n",
      "Epoch 00002: saving model to /Users/abpwrs/NLP-DL/model/uncorrected_2018-11-03_20:02:22/cp-0002.ckpt\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 3s 28us/step - loss: 0.2856 - mean_absolute_error: 0.2818 - mean_squared_error: 0.1889 - categorical_crossentropy: 0.2856 - categorical_accuracy: 0.9869 - val_loss: 0.2909 - val_mean_absolute_error: 0.2771 - val_mean_squared_error: 0.1848 - val_categorical_crossentropy: 0.2909 - val_categorical_accuracy: 0.9832\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 3s 29us/step - loss: 0.2814 - mean_absolute_error: 0.2673 - mean_squared_error: 0.1811 - categorical_crossentropy: 0.2814 - categorical_accuracy: 0.9836 - val_loss: 0.2901 - val_mean_absolute_error: 0.2569 - val_mean_squared_error: 0.1756 - val_categorical_crossentropy: 0.2901 - val_categorical_accuracy: 0.9831\n",
      "\n",
      "Epoch 00004: saving model to /Users/abpwrs/NLP-DL/model/uncorrected_2018-11-03_20:02:22/cp-0004.ckpt\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 3s 30us/step - loss: 0.2795 - mean_absolute_error: 0.2631 - mean_squared_error: 0.1807 - categorical_crossentropy: 0.2795 - categorical_accuracy: 0.9818 - val_loss: 0.2899 - val_mean_absolute_error: 0.2543 - val_mean_squared_error: 0.1762 - val_categorical_crossentropy: 0.2899 - val_categorical_accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b080ae58cc0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=500,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52659/52659 [==============================] - 3s 49us/step\n",
      "[0.2899430568366193,\n",
      " 0.2542817351034087,\n",
      " 0.1761526752725759,\n",
      " 0.2899430568366193,\n",
      " 0.98254809245176]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "pp(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = vecs.reshape(vecs.shape[0], 1, FEATUR_VECTOR_LENGTH)\n",
    "result = {}\n",
    "for index in range(NUM_CLASSES):\n",
    "    temp_dict = {}\n",
    "    y_pred = model.predict(temp).astype(np.int32)\n",
    "    true_pos = true_neg = 0\n",
    "    pos = neg = 0\n",
    "    for p in range(len(y_pred)):\n",
    "        if labels[p][index] == 1:\n",
    "            pos += 1\n",
    "            if y_pred[p][index] == 1:\n",
    "                true_pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "            if y_pred[p][index] == 0:\n",
    "                true_neg += 1\n",
    "        \n",
    "    temp_dict[\"TP\"] = true_pos\n",
    "    temp_dict[\"TN\"] = true_neg\n",
    "    temp_dict[\"P\"] = pos\n",
    "    temp_dict[\"N\"] = neg\n",
    "    result[index] = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a3956400167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"confusion.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "pp(result)\n",
    "with open(os.path.join(data_dir, \"confusion.pkl\"), \"wb\") as f:\n",
    "    json.dump(result,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
